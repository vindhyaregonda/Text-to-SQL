{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: torch in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: duckdb in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: sqlglot[rs] in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (25.17.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: sqlglotrs==0.2.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlglot[rs]) (0.2.9)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.11.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.93.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (2.22.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (4.23.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-generativeai) (1.10.11)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core->google-generativeai) (1.59.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=2.15.0->google-generativeai) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.15.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.66.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httplib2<1.dev0,>=0.15.0->google-api-python-client->google-generativeai) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch \"sqlglot[rs]\" duckdb google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sqlite3\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import sqlglot\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini API Key\n",
    "genai.configure(api_key='API_KEY')\n",
    "\n",
    "# Load and parse the train.json file\n",
    "with open('D:/Downloads/Text-to-SQL/train/train.json', 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract schema from sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract schema from the .sqlite file\n",
    "def connect_to_database(db_path):\n",
    "    \"\"\"Establish a connection to the SQLite database.\"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        return conn\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_table_names(conn):\n",
    "    \"\"\"Retrieve the names of all tables in the database.\"\"\"\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "        tables = cur.fetchall()\n",
    "        return [table[0] for table in tables]  # Extract table names from tuples\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error retrieving table names: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_column_names(conn, table_name):\n",
    "    \"\"\"Retrieve the column names for a given table.\"\"\"\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        # cur.execute(f\"PRAGMA table_info({table_name});\")\n",
    "        cur.execute(f\"PRAGMA table_info(\\\"{table_name}\\\");\")\n",
    "        schema = cur.fetchall()\n",
    "        return [column[1] for column in schema]  # Extract column names from tuples\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Error retrieving columns for table {table_name}: {e}\")\n",
    "        return []\n",
    "\n",
    "def extract_schema(conn):\n",
    "    \"\"\"Extract the schema of all tables and store it in a dictionary.\"\"\"\n",
    "    schema_dict = {}\n",
    "    table_names = get_table_names(conn)\n",
    "    \n",
    "    for table_name in table_names:\n",
    "        columns = get_column_names(conn, table_name)\n",
    "        schema_dict[table_name] = columns\n",
    "    \n",
    "    return schema_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the SQL syntax (sqlglot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_sql(sql_query):\n",
    "    \"\"\"Validate the SQL query using sqlglot.\"\"\"\n",
    "    try:\n",
    "        sqlglot.parse_one(sql_query)\n",
    "        return True\n",
    "    except sqlglot.errors.ParseError as e:\n",
    "        print(f\"SQL syntax error: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data from SQL query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_query(sql_query, db_path):\n",
    "    \"\"\"Execute the SQL query against the SQLite database.\"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # print(conn)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(sql_query)        \n",
    "        # rows = cursor.fetchall()    \n",
    "        rows = cursor.fetchmany(5)  \n",
    "\n",
    "        return rows\n",
    "    \n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_template = \"\"\"\n",
    "# \"Database schema will be given in dict format where key is the table name and value is the list of columns in the table\n",
    "# {schema}\n",
    "# Example: dict 'tablename': ['col1', 'col2', 'col3']\n",
    "\n",
    "# Here are a few examples, \"Q\" represents the question and \"A\" represents the corresponding SQL-query :\n",
    "# Q: List out the account numbers of female clients who are oldest and has lowest average salary, calculate the gap between this lowest average salary with the highest average salary?\n",
    "# A: SELECT T1.account_id , ( SELECT MAX(A11) - MIN(A11) FROM district ) FROM account AS T1 INNER JOIN district AS T2 ON T1.district_id = T2.district_id WHERE T2.district_id = ( SELECT district_id FROM client WHERE gender = 'F' ORDER BY birth_date ASC LIMIT 1 ) ORDER BY T2.A11 DESC LIMIT 1\n",
    "\n",
    "# Q: For the branch which located in the south Bohemia with biggest number of inhabitants, what is the percentage of the male clients?\n",
    "# A: SELECT CAST(SUM(T1.gender = 'M') AS REAL) * 100 / COUNT(T1.client_id) FROM client AS T1 INNER JOIN district AS T2 ON T1.district_id = T2.district_id WHERE T2.A3 = 'south Bohemia' GROUP BY T2.A4 ORDER BY T2.A4 DESC LIMIT 1\n",
    "\n",
    "# Q: \"For the client who first applied the loan in 1993/7/5, what is the increase rate of his/her account balance from 1993/3/22 to 1998/12/27?\n",
    "# A: SELECT CAST((SUM(IIF(T3.date = '1998-12-27', T3.balance, 0)) - SUM(IIF(T3.date = '1993-03-22', T3.balance, 0))) AS REAL) * 100 / SUM(IIF(T3.date = '1993-03-22', T3.balance, 0)) FROM loan AS T1 INNER JOIN account AS T2 ON T1.account_id = T2.account_id INNER JOIN trans AS T3 ON T3.account_id = T2.account_id WHERE T1.date = '1993-07-05'\n",
    "\n",
    "# Using valid SQL, answer the following question based on the tables provided above.\n",
    "# It is important to use qualified column names in the SQL-query, meaning the form \"SELECT table_name.column_name FROM table_name;\n",
    "\n",
    "\n",
    "# Hint helps you to write the correct SQL query.\n",
    "# Question: {question}\n",
    "# Hint: {evidence}\n",
    "# DO NOT return anything else except the SQL query. Make sure the SQL query is compatible with SQLite syntax. No need to mentio ```sql\"\n",
    "# \"\"\"\n",
    "\n",
    "# def get_gemini_response(question, evidence, schema):\n",
    "#     \"\"\"Generate SQL query using Gemini Pro.\"\"\"\n",
    "   \n",
    "#     prompt = prompt_template.format(schema=schema, question=question, evidence=evidence)\n",
    "#     model = genai.GenerativeModel('gemini-pro')\n",
    "#     response = model.generate_content([prompt])\n",
    "#     return response.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pay close attention on which column is in which table. if context contains more than one tables then create a query by performing JOIN operation only using the column unitid for the tables.\\\n",
    "Follow these Instructions for creating syntactically correct SQL query:\\\n",
    "- Be sure not to query for columns that do not exist in the tables and use alias only where required.\\\n",
    "- Always use the column 'instnm' associated with the 'unitid' in the generated query.\\\n",
    "- Whenever asked for Institute Names, return the institute names using column 'instnm' associated with the 'unitid' in the generated query.\\\n",
    "- Likewise, when asked about the average (AVG function) or ratio, ensure the appropriate aggregation function is used.\\\n",
    "- Pay close attention to the filtering criteria mentioned in the question and incorporate them using the WHERE clause in your SQL query.\\\n",
    "- If the question involves multiple conditions, use logical operators such as AND, OR to combine them effectively.\\\n",
    "- When dealing with date or timestamp columns, use appropriate date functions (e.g., DATE_PART, EXTRACT) for extracting specific parts of the date or performing date arithmetic.\\\n",
    "- If the question involves grouping of data (e.g., finding totals or averages for different categories), use the GROUP BY clause along with appropriate aggregate functions.\\\n",
    "- Consider using aliases for tables and columns to improve readability of the query, especially in case of complex joins or subqueries.\\\n",
    "- If necessary, use subqueries or common table expressions (CTEs) to break down the problem into smaller, more manageable parts.\n",
    "\"\"\" \n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\"Database schema will be given in dict format where key is the table name and value is the list of columns in the table\n",
    "{schema}\n",
    "Example: dict 'tablename': ['col1', 'col2', 'col3']\n",
    "\n",
    "Here are a few examples, you can use them to generate the SQL query:\n",
    "\n",
    "\"question\": \"Rank schools by their average score in Writing where the score is greater than 499, showing their charter numbers.\",\n",
    "\"evidence\": \"Valid charter number means the number is not null\",\n",
    "\"SQL\": \"SELECT CharterNum, AvgScrWrite, RANK() OVER (ORDER BY AvgScrWrite DESC) AS WritingScoreRank FROM schools AS T1  INNER JOIN satscores AS T2 ON T1.CDSCode = T2.cds WHERE T2.AvgScrWrite > 499 AND CharterNum is not null\",\n",
    "   \n",
    "\"question\": \"Among the weekly issuance accounts, how many have a loan of under 200000?\",\n",
    "\"evidence\": \"frequency = 'POPLATEK TYDNE' stands for weekly issuance\",\n",
    "\"SQL\": \"SELECT COUNT(T1.account_id) FROM loan AS T1 INNER JOIN account AS T2 ON T1.account_id = T2.account_id WHERE T2.frequency = 'POPLATEK TYDNE' AND T1.amount < 200000\",\n",
    "\n",
    "Evidence helps you to write the correct SQL query.\n",
    "Question: {question}\n",
    "Evidence: {evidence}\n",
    "DO NOT return anything else except the SQL query. Make sure the SQL query is compatible with SQLite syntax. No need to mentio ```sql\"\n",
    "\"\"\"\n",
    "\n",
    "def get_gemini_response(question, evidence, schema):\n",
    "    \"\"\"Generate SQL query using Gemini Pro.\"\"\"\n",
    "   \n",
    "    prompt = prompt_template.format(schema=schema, question=question, evidence=evidence)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content([prompt])\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template2 = \"\"\"\n",
    "Given the question, evidence, schema, and SQL query, you need to verify and correct the SQL query if necessary. \n",
    "\n",
    "1. Check if the SQL query correctly matches the question based on the provided schema.\n",
    "2. Ensure that all table names and column names in the query are correct according to the schema.\n",
    "3. If the query is correct, return it as is. If not, modify the query to correct any errors.\n",
    "\n",
    "Do not include any additional information or explanations—return only the corrected SQL query.\n",
    "\n",
    "The database schema is provided in dict format, where each key is a table name and each value is a list of columns for that table:\n",
    "{schema}\n",
    "Example format: dict 'table_name': ['column1', 'column2', 'column3']\n",
    "\n",
    "Question: {question}\n",
    "Hint: {evidence}\n",
    "Query: {query}\n",
    "\n",
    "Only return the SQL query—nothing else. Make sure the SQL query is compatible with SQLite syntax.\n",
    "\"\"\"\n",
    "\n",
    "def get_gemini_response2(question, evidence, schema, query):\n",
    "    \"\"\"Generate SQL query using Gemini Pro.\"\"\"\n",
    "   \n",
    "    prompt = prompt_template2.format(schema=schema, question=question, evidence=evidence, query=query)\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    response = model.generate_content([prompt])\n",
    "    return response.text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "\n",
    "1. The provided code is designed to process multiple instances of data, where each instance involves generating and refining SQL queries based on a given question, evidence, and database schema. \n",
    "2. The generated SQL queries are then validated and executed against the actual SQL queries, and the results are stored in a CSV file. \n",
    "3. The process introduces a delay between each instance to control the processing rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql_query(question, evidence, schema_dict):\n",
    "    \"\"\"Generate SQL query based on question, evidence, and schema.\"\"\"\n",
    "    generated_sql = get_gemini_response(question=question, evidence=evidence, schema=schema_dict)\n",
    "    converted_query = generated_sql.replace(\"```sql \", \"\").replace(\"```\", \"\").replace('sql', \"\")\n",
    "    return converted_query\n",
    "\n",
    "def refine_sql_query(question, evidence, schema_dict, initial_query):\n",
    "    \"\"\"Refine the SQL query using another model.\"\"\"\n",
    "    new_query = get_gemini_response2(question=question, evidence=evidence, schema=schema_dict, query=initial_query)\n",
    "    refined_query = new_query.replace(\"```sql \", \"\").replace(\"```\", \"\").replace('sql', \"\")\n",
    "    return refined_query\n",
    "\n",
    "def process_instance(instance, db_base_path):\n",
    "    \"\"\"Process a single instance: generate SQL, validate, execute, and store results.\"\"\"\n",
    "    db_id = instance['db_id']\n",
    "    question = instance['question']\n",
    "    evidence = instance['evidence']\n",
    "    SQL_query = instance[\"SQL\"]\n",
    "\n",
    "    # db_folder = f'{db_base_path}/{db_id}/database_description'\n",
    "    sql_schema_path = f'{db_base_path}/{db_id}/{db_id}.sqlite'\n",
    "\n",
    "    conn = connect_to_database(sql_schema_path)\n",
    "    \n",
    "    if conn:\n",
    "        schema_dict = extract_schema(conn)\n",
    "\n",
    "    # Generate and refine the SQL query\n",
    "    generated_sql = generate_sql_query(question, evidence, schema_dict)\n",
    "    refined_sql = refine_sql_query(question, evidence, schema_dict, generated_sql)\n",
    "\n",
    "    # Validate the refined SQL\n",
    "    validation_successful = validate_sql(refined_sql)\n",
    "\n",
    "    # Execute the actual and generated SQL queries\n",
    "    results_actual = execute_sql_query(SQL_query, sql_schema_path)\n",
    "    results_gen = execute_sql_query(refined_sql, sql_schema_path)\n",
    "\n",
    "    # Return the results as a dictionary\n",
    "    return {\n",
    "        \"gen_query\": refined_sql,\n",
    "        \"actual_query\": SQL_query,\n",
    "        \"gen_output\": results_gen,\n",
    "        \"actual_output\": results_actual,\n",
    "        \"validation\": \"yes\" if validation_successful else \"no\"\n",
    "    }\n",
    "\n",
    "def process_multiple_instances(data, n=10, db_base_path='D:/Downloads/Text-to-SQL/train/train_databases', delay=4):\n",
    "    \"\"\"Process multiple instances, introduce a delay, and store the results in a DataFrame.\"\"\"\n",
    "    selected_instances = random.sample(data, n)\n",
    "    results_list = []\n",
    "\n",
    "    for idx, instance in enumerate(selected_instances):\n",
    "        print(f\"Processing Instance {idx + 1}\")\n",
    "        result = process_instance(instance, db_base_path)\n",
    "        results_list.append(result)\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Introduce a delay between processing each instance\n",
    "        time.sleep(delay)\n",
    "\n",
    "    # Convert the results list to a DataFrame and save it as a CSV file\n",
    "    df = pd.DataFrame(results_list)\n",
    "    df.to_csv('submit4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Instance 1\n",
      "Database error: near \"transaction\": syntax error\n",
      "--------------------------------------------------\n",
      "Processing Instance 2\n",
      "--------------------------------------------------\n",
      "Processing Instance 3\n",
      "--------------------------------------------------\n",
      "Processing Instance 4\n",
      "--------------------------------------------------\n",
      "Processing Instance 5\n",
      "Database error: aggregate functions are not allowed in the GROUP BY clause\n",
      "--------------------------------------------------\n",
      "Processing Instance 6\n"
     ]
    }
   ],
   "source": [
    "process_multiple_instances(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**:\n",
    "\n",
    "1. The code provided is a script designed to process multiple CSV files that contain SQL query results, validate the correctness of the generated SQL queries against actual SQL queries, and analyze the results. \n",
    "2. The script performs several key tasks, including reading and concatenating CSV files, removing duplicate entries, validating the generated SQL outputs, and counting the occurrences of correct outputs. The final results are printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final DataFrame shape: (30, 6)\n",
      "Correct output counts:\n",
      " 0    22\n",
      "1     8\n",
      "Name: correct_output, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_and_concatenate_csv_files(base_path, file_prefix, num_files):\n",
    "    \"\"\"Read multiple CSV files, concatenate them into a single DataFrame.\"\"\"\n",
    "    df_final = None\n",
    "\n",
    "    for i in range(1, num_files + 1):\n",
    "        file_path = os.path.join(base_path, f'{file_prefix}{i}.csv')\n",
    "        df = pd.read_csv(file_path)\n",
    "        if i == 1:\n",
    "            df_final = df\n",
    "        else:\n",
    "            df_final = pd.concat([df_final, df], ignore_index=True)\n",
    "    df_final = df_final.drop_duplicates()\n",
    "    return df_final\n",
    "\n",
    "def validate_outputs(df):\n",
    "    \"\"\"Add a column to the DataFrame indicating whether the generated output matches the actual output.\"\"\"\n",
    "    df['correct_output'] = df.apply(lambda row: 1 if row['gen_output'] == row['actual_output'] else 0, axis=1)\n",
    "    return df\n",
    "\n",
    "def process_csv_files(base_path, file_prefix='submit', num_files=20):\n",
    "    \"\"\"Main function to process CSV files, remove duplicates, validate outputs, and count results.\"\"\"\n",
    "    df_final = read_and_concatenate_csv_files(base_path, file_prefix, num_files)\n",
    "\n",
    "    df_final = validate_outputs(df_final)\n",
    "    correct_output_counts = df_final['correct_output'].value_counts()\n",
    "    return df_final, correct_output_counts\n",
    "\n",
    "# Define the base path where the CSV files are located\n",
    "base_path = 'D:/Downloads/Text-to-SQL/'\n",
    "\n",
    "# Call the main processing function\n",
    "df_final, correct_output_counts = process_csv_files(base_path, file_prefix='submit',num_files=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Final DataFrame shape:\", df_final.shape)\n",
    "print(\"Correct output counts:\\n\", correct_output_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate: 0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Success rate\n",
    "print(\"Success rate:\", correct_output_counts[1] / df_final.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
